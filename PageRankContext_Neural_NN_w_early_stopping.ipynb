{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PageRankContext_Neural_NN_w_early_stopping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5U7t4YqnxgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "import keras\n",
        "\n",
        "\n",
        "# In[61]:\n",
        "\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Dropout, Activation\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "np.random.seed(1)     \n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6q9OecKoAVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TEST_NAME = \"KMeans\"\n",
        "TEST_NAME = \"PageRank\"\n",
        "#TEST_NAME = \"SGD\"\n",
        "\n",
        "#plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    #acc = history.history['r2_score_other']\n",
        "    #val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(loss) + 1)\n",
        "\n",
        "    #plt.figure(figsize=(12, 5))\n",
        "    #plt.subplot(1, 2, 1)\n",
        "    #plt.plot(x, acc, 'b', label='Training r2_score')\n",
        "    #plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    #plt.title('Training and validation accuracy')\n",
        "    #plt.legend()\n",
        "    #plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "# In[42]:\n",
        "\n",
        "def add_context(data_df, context = 0):\n",
        "\n",
        "    L = len(data_df)\n",
        "    cols = list(data_df.columns)\n",
        "\n",
        "    context_data = []\n",
        "    \n",
        "    row_1 = np.asarray(data_df.iloc[0,:])\n",
        "    row_1 = np.reshape(row_1,(1,-1))\n",
        "    row_1 = pd.DataFrame(row_1, columns=cols)\n",
        "    #pad data with data[0] context times\n",
        "    data = pd.concat([row_1]*context + [data_df])\n",
        "    \n",
        "    try:\n",
        "        del data[0]\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    data = data.to_numpy()\n",
        "    \n",
        "    \n",
        "    for fi in range(context, len(data)):\n",
        "        frame = data[fi-context:fi+1].flatten()\n",
        "        context_data.append(frame)\n",
        "    \n",
        "    return pd.DataFrame(context_data, columns = cols*(context+1))\n",
        "\n",
        "def read_dataset(filename):\n",
        "    dataset = pd.read_csv(filename)\n",
        "    return dataset\n",
        "\n",
        "def get_data_labels(df, context = 0):\n",
        "    label = df['flow_size']\n",
        "    try:\n",
        "      del df['job']\n",
        "    except:\n",
        "      pass\n",
        "    df = add_context(df, context)\n",
        "    df.iloc[:, -1] = 0\n",
        "    #add context to labels\n",
        "    return df, label\n",
        "\n",
        "\n",
        "\n",
        "# # Neural Network\n",
        "\n",
        "\n",
        "#from keras import optimizers\n",
        "#adam = optimizers.Adam(lr=0.9)\n",
        "\n",
        "\n",
        "# In[90]:\n",
        "\n",
        "\n",
        "#r2 score used in paper. 1 is best. -1 is bad.\n",
        "\n",
        "def r2_score_other(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "\n",
        "#from https://stackoverflow.com/questions/45250100/kerasregressor-coefficient-of-determination-r2-score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5ePTgxooHuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "train_df = read_dataset(TEST_NAME+'_training.csv')\n",
        "test_df = read_dataset(TEST_NAME+'_test.csv')\n",
        "validation_df = read_dataset(TEST_NAME+'_validation.csv')\n",
        "\n",
        "#all will have same columns\n",
        "cols = train_df.columns\n",
        "\n",
        "#scale and convert to df\n",
        "train_df = scaler.fit_transform(train_df)\n",
        "train_df = pd.DataFrame(train_df, columns = cols)\n",
        "\n",
        "test_df = scaler.transform(test_df)\n",
        "test_df = pd.DataFrame(test_df, columns = cols)\n",
        "\n",
        "validation_df = scaler.transform(validation_df)\n",
        "validation_df = pd.DataFrame(validation_df, columns = cols)\n",
        "\n",
        "context = 1\n",
        "\n",
        "train_x, train_y = get_data_labels(train_df, context)\n",
        "test_x, test_y = get_data_labels(test_df, context)\n",
        "validation_x, validation_y = get_data_labels(validation_df, context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcvJZ6NO097T",
        "colab_type": "code",
        "outputId": "9c7673fb-c09f-47df-e7e7-019a9b366043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x.shape, train_y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((54646, 16), (54646,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfuz--xvOGwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define callback for early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
        "\n",
        "#define callback for saving best model\n",
        "model_name = 'nn_model_' + TEST_NAME + str(context) + 'context' + '.h5'\n",
        "best_model = ModelCheckpoint(model_name, monitor='val_loss',mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-j7xHv3oMV-",
        "colab_type": "code",
        "outputId": "23844770-c071-4d91-ae01-209cd4666047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# In[102]:\n",
        "\n",
        "'''\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=train_x.shape[1],activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Dense(1, activation='relu'))\n",
        "model.summary()\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam', metrics = [r2_score_other])\n",
        "model.fit(train_x, train_y, epochs=250, batch_size=10)\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=train_x.shape[1], activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "history = model.fit(train_x, train_y, epochs=100, \\\n",
        "                      validation_data = (validation_x, validation_y), \\\n",
        "                      batch_size=10, verbose=2, callbacks = [early_stop, best_model])\n",
        "\n",
        "#plot_history(history)\n",
        "\n",
        "#error metric\n",
        "model.evaluate(test_x, test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54646 samples, validate on 15695 samples\n",
            "Epoch 1/100\n",
            " - 6s - loss: 0.0066 - val_loss: 0.0021\n",
            "Epoch 2/100\n",
            " - 6s - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 3/100\n",
            " - 6s - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 4/100\n",
            " - 6s - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 5/100\n",
            " - 6s - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 6/100\n",
            " - 6s - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 7/100\n",
            " - 6s - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 8/100\n",
            " - 6s - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 9/100\n",
            " - 6s - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 10/100\n",
            " - 6s - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 11/100\n",
            " - 6s - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            " - 6s - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 13/100\n",
            " - 6s - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 14/100\n",
            " - 6s - loss: 0.0010 - val_loss: 9.5256e-04\n",
            "Epoch 15/100\n",
            " - 6s - loss: 9.9182e-04 - val_loss: 9.4809e-04\n",
            "Epoch 16/100\n",
            " - 6s - loss: 9.8574e-04 - val_loss: 9.4579e-04\n",
            "Epoch 17/100\n",
            " - 6s - loss: 0.0010 - val_loss: 9.2373e-04\n",
            "Epoch 18/100\n",
            " - 6s - loss: 9.6696e-04 - val_loss: 9.2471e-04\n",
            "Epoch 19/100\n",
            " - 6s - loss: 9.6628e-04 - val_loss: 0.0010\n",
            "Epoch 20/100\n",
            " - 6s - loss: 9.7086e-04 - val_loss: 9.3538e-04\n",
            "Epoch 21/100\n",
            " - 6s - loss: 9.3623e-04 - val_loss: 9.1674e-04\n",
            "Epoch 22/100\n",
            " - 6s - loss: 9.3635e-04 - val_loss: 9.0798e-04\n",
            "Epoch 23/100\n",
            " - 6s - loss: 9.3036e-04 - val_loss: 0.0010\n",
            "Epoch 24/100\n",
            " - 6s - loss: 9.3876e-04 - val_loss: 8.9497e-04\n",
            "Epoch 25/100\n",
            " - 6s - loss: 9.3554e-04 - val_loss: 8.8154e-04\n",
            "Epoch 26/100\n",
            " - 6s - loss: 9.1809e-04 - val_loss: 8.9845e-04\n",
            "Epoch 27/100\n",
            " - 6s - loss: 9.3802e-04 - val_loss: 9.7282e-04\n",
            "Epoch 28/100\n",
            " - 6s - loss: 9.4136e-04 - val_loss: 0.0010\n",
            "Epoch 29/100\n",
            " - 6s - loss: 9.2489e-04 - val_loss: 9.4418e-04\n",
            "Epoch 30/100\n",
            " - 6s - loss: 9.1745e-04 - val_loss: 9.3187e-04\n",
            "Epoch 31/100\n",
            " - 6s - loss: 9.1654e-04 - val_loss: 9.6024e-04\n",
            "Epoch 32/100\n",
            " - 6s - loss: 9.2857e-04 - val_loss: 9.1393e-04\n",
            "Epoch 33/100\n",
            " - 6s - loss: 9.2315e-04 - val_loss: 9.6551e-04\n",
            "Epoch 34/100\n",
            " - 6s - loss: 9.0666e-04 - val_loss: 8.7412e-04\n",
            "Epoch 35/100\n",
            " - 6s - loss: 9.1824e-04 - val_loss: 9.5409e-04\n",
            "Epoch 36/100\n",
            " - 6s - loss: 9.1785e-04 - val_loss: 8.7047e-04\n",
            "Epoch 37/100\n",
            " - 6s - loss: 9.6177e-04 - val_loss: 8.7958e-04\n",
            "Epoch 38/100\n",
            " - 6s - loss: 9.2227e-04 - val_loss: 9.0211e-04\n",
            "Epoch 39/100\n",
            " - 6s - loss: 9.1876e-04 - val_loss: 8.9714e-04\n",
            "Epoch 40/100\n",
            " - 6s - loss: 9.2558e-04 - val_loss: 8.6121e-04\n",
            "Epoch 41/100\n",
            " - 6s - loss: 9.0410e-04 - val_loss: 9.0177e-04\n",
            "Epoch 42/100\n",
            " - 6s - loss: 9.0875e-04 - val_loss: 0.0010\n",
            "Epoch 43/100\n",
            " - 6s - loss: 9.0829e-04 - val_loss: 9.0478e-04\n",
            "Epoch 44/100\n",
            " - 6s - loss: 8.8492e-04 - val_loss: 9.5547e-04\n",
            "Epoch 45/100\n",
            " - 6s - loss: 9.1111e-04 - val_loss: 8.5861e-04\n",
            "Epoch 46/100\n",
            " - 6s - loss: 9.0612e-04 - val_loss: 8.5500e-04\n",
            "Epoch 47/100\n",
            " - 6s - loss: 9.0236e-04 - val_loss: 8.6721e-04\n",
            "Epoch 48/100\n",
            " - 6s - loss: 9.0487e-04 - val_loss: 8.6061e-04\n",
            "Epoch 49/100\n",
            " - 6s - loss: 9.1688e-04 - val_loss: 9.1520e-04\n",
            "Epoch 50/100\n",
            " - 6s - loss: 9.1066e-04 - val_loss: 9.1750e-04\n",
            "Epoch 51/100\n",
            " - 6s - loss: 8.9640e-04 - val_loss: 0.0010\n",
            "Epoch 52/100\n",
            " - 6s - loss: 8.9067e-04 - val_loss: 9.0855e-04\n",
            "Epoch 53/100\n",
            " - 6s - loss: 9.1213e-04 - val_loss: 9.1244e-04\n",
            "Epoch 54/100\n",
            " - 6s - loss: 8.9459e-04 - val_loss: 8.7069e-04\n",
            "Epoch 55/100\n",
            " - 6s - loss: 9.2588e-04 - val_loss: 9.5703e-04\n",
            "Epoch 56/100\n",
            " - 6s - loss: 9.3002e-04 - val_loss: 9.1303e-04\n",
            "Epoch 57/100\n",
            " - 6s - loss: 9.0029e-04 - val_loss: 9.2110e-04\n",
            "Epoch 58/100\n",
            " - 6s - loss: 9.0904e-04 - val_loss: 8.6373e-04\n",
            "Epoch 59/100\n",
            " - 6s - loss: 9.2304e-04 - val_loss: 8.6051e-04\n",
            "Epoch 60/100\n",
            " - 6s - loss: 8.8199e-04 - val_loss: 9.1948e-04\n",
            "Epoch 61/100\n",
            " - 6s - loss: 8.7922e-04 - val_loss: 9.0038e-04\n",
            "Epoch 62/100\n",
            " - 6s - loss: 9.4416e-04 - val_loss: 8.5724e-04\n",
            "Epoch 63/100\n",
            " - 6s - loss: 9.1847e-04 - val_loss: 8.8571e-04\n",
            "Epoch 64/100\n",
            " - 6s - loss: 9.0488e-04 - val_loss: 0.0010\n",
            "Epoch 65/100\n",
            " - 6s - loss: 8.9826e-04 - val_loss: 8.7673e-04\n",
            "Epoch 66/100\n",
            " - 6s - loss: 8.8881e-04 - val_loss: 9.3858e-04\n",
            "Epoch 67/100\n",
            " - 6s - loss: 9.1485e-04 - val_loss: 8.9275e-04\n",
            "Epoch 68/100\n",
            " - 6s - loss: 9.0683e-04 - val_loss: 8.9579e-04\n",
            "Epoch 69/100\n",
            " - 6s - loss: 9.0315e-04 - val_loss: 8.7443e-04\n",
            "Epoch 70/100\n",
            " - 6s - loss: 8.8774e-04 - val_loss: 9.2439e-04\n",
            "Epoch 71/100\n",
            " - 6s - loss: 8.7742e-04 - val_loss: 9.3067e-04\n",
            "Epoch 72/100\n",
            " - 6s - loss: 8.8477e-04 - val_loss: 8.6902e-04\n",
            "Epoch 73/100\n",
            " - 6s - loss: 9.0056e-04 - val_loss: 8.9674e-04\n",
            "Epoch 74/100\n",
            " - 6s - loss: 8.8398e-04 - val_loss: 9.0610e-04\n",
            "Epoch 75/100\n",
            " - 6s - loss: 8.8463e-04 - val_loss: 8.7393e-04\n",
            "Epoch 76/100\n",
            " - 6s - loss: 8.8641e-04 - val_loss: 9.2088e-04\n",
            "Epoch 77/100\n",
            " - 6s - loss: 8.9890e-04 - val_loss: 8.4815e-04\n",
            "Epoch 78/100\n",
            " - 6s - loss: 8.8261e-04 - val_loss: 8.8182e-04\n",
            "Epoch 79/100\n",
            " - 6s - loss: 8.8529e-04 - val_loss: 8.8310e-04\n",
            "Epoch 80/100\n",
            " - 6s - loss: 9.0603e-04 - val_loss: 9.2347e-04\n",
            "Epoch 81/100\n",
            " - 6s - loss: 9.2039e-04 - val_loss: 8.4876e-04\n",
            "Epoch 82/100\n",
            " - 6s - loss: 9.0349e-04 - val_loss: 8.7434e-04\n",
            "Epoch 83/100\n",
            " - 6s - loss: 8.9800e-04 - val_loss: 8.7930e-04\n",
            "Epoch 84/100\n",
            " - 6s - loss: 8.8879e-04 - val_loss: 8.7408e-04\n",
            "Epoch 85/100\n",
            " - 6s - loss: 8.9317e-04 - val_loss: 8.9216e-04\n",
            "Epoch 86/100\n",
            " - 6s - loss: 8.9749e-04 - val_loss: 8.4721e-04\n",
            "Epoch 87/100\n",
            " - 6s - loss: 8.7156e-04 - val_loss: 8.7515e-04\n",
            "Epoch 88/100\n",
            " - 6s - loss: 8.8131e-04 - val_loss: 8.6409e-04\n",
            "Epoch 89/100\n",
            " - 6s - loss: 8.9660e-04 - val_loss: 9.4169e-04\n",
            "Epoch 90/100\n",
            " - 6s - loss: 8.9444e-04 - val_loss: 8.7985e-04\n",
            "Epoch 91/100\n",
            " - 6s - loss: 9.0572e-04 - val_loss: 8.6510e-04\n",
            "Epoch 92/100\n",
            " - 6s - loss: 8.7301e-04 - val_loss: 8.3175e-04\n",
            "Epoch 93/100\n",
            " - 6s - loss: 8.8395e-04 - val_loss: 8.8409e-04\n",
            "Epoch 94/100\n",
            " - 6s - loss: 8.9896e-04 - val_loss: 8.2365e-04\n",
            "Epoch 95/100\n",
            " - 6s - loss: 8.8552e-04 - val_loss: 9.0236e-04\n",
            "Epoch 96/100\n",
            " - 6s - loss: 9.1454e-04 - val_loss: 8.6412e-04\n",
            "Epoch 97/100\n",
            " - 6s - loss: 8.8338e-04 - val_loss: 8.5807e-04\n",
            "Epoch 98/100\n",
            " - 6s - loss: 8.9376e-04 - val_loss: 8.7214e-04\n",
            "Epoch 99/100\n",
            " - 6s - loss: 8.7640e-04 - val_loss: 8.6300e-04\n",
            "Epoch 100/100\n",
            " - 6s - loss: 8.7980e-04 - val_loss: 8.4691e-04\n",
            "14814/14814 [==============================] - 0s 15us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0008432364022130476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJc82JNX_SKs",
        "colab_type": "code",
        "outputId": "94cd05de-effb-42fb-8254-9faa685219c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3GHvnnVoOVV",
        "colab_type": "code",
        "outputId": "73a9c8a5-0cf1-4216-c248-18c7163f281c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#save final model also\n",
        "model.save('final'+model_name)\n",
        "\n",
        "pred_y = model.predict(test_x)\n",
        "score = r2_score(test_y, pred_y)\n",
        "print(f'Test r2 score: {score}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test r2 score: 0.9230956554054428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvZk03Whn6dD",
        "colab_type": "code",
        "outputId": "bada21ad-e132-4497-97bf-78c20c9f45ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "saved_model = load_model('finalnn_model_PageRank1context.h5')\n",
        "pred_y = saved_model.predict(test_x)\n",
        "score = r2_score(test_y, pred_y)\n",
        "print(f'Test r2 score: {score}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test r2 score: 0.9230956554054428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWZNK1BAvdH-",
        "colab_type": "code",
        "outputId": "da38418c-f900-47a6-f1e8-c6f427da646d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_x, train_y, epochs=100, \\\n",
        "                      validation_data = (validation_x, validation_y), \\\n",
        "                      batch_size=10, verbose=2, callbacks = [early_stop, best_model])\n",
        "\n",
        "pred_y = model.predict(test_x)\n",
        "score = r2_score(test_y, pred_y)\n",
        "print(f'Test r2 score: {score}')"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54646 samples, validate on 15695 samples\n",
            "Epoch 1/100\n",
            " - 6s - loss: 8.8314e-04 - val_loss: 8.4001e-04\n",
            "Epoch 2/100\n",
            " - 6s - loss: 8.8094e-04 - val_loss: 8.5468e-04\n",
            "Epoch 3/100\n",
            " - 6s - loss: 8.7457e-04 - val_loss: 8.8203e-04\n",
            "Epoch 4/100\n",
            " - 6s - loss: 8.9701e-04 - val_loss: 8.7858e-04\n",
            "Epoch 5/100\n",
            " - 6s - loss: 9.0467e-04 - val_loss: 9.0176e-04\n",
            "Epoch 6/100\n",
            " - 6s - loss: 8.8233e-04 - val_loss: 8.4948e-04\n",
            "Epoch 7/100\n",
            " - 6s - loss: 8.8587e-04 - val_loss: 8.6156e-04\n",
            "Epoch 8/100\n",
            " - 6s - loss: 8.7894e-04 - val_loss: 9.1089e-04\n",
            "Epoch 9/100\n",
            " - 6s - loss: 8.9530e-04 - val_loss: 9.3459e-04\n",
            "Epoch 10/100\n",
            " - 6s - loss: 8.7954e-04 - val_loss: 8.5337e-04\n",
            "Epoch 11/100\n",
            " - 6s - loss: 8.9358e-04 - val_loss: 8.7116e-04\n",
            "Epoch 12/100\n",
            " - 6s - loss: 8.6110e-04 - val_loss: 8.5881e-04\n",
            "Epoch 13/100\n",
            " - 6s - loss: 8.7985e-04 - val_loss: 9.7765e-04\n",
            "Epoch 14/100\n",
            " - 6s - loss: 8.8875e-04 - val_loss: 8.6442e-04\n",
            "Epoch 15/100\n",
            " - 6s - loss: 8.7354e-04 - val_loss: 8.6909e-04\n",
            "Epoch 16/100\n",
            " - 6s - loss: 9.0084e-04 - val_loss: 8.5814e-04\n",
            "Epoch 17/100\n",
            " - 6s - loss: 8.7455e-04 - val_loss: 8.7863e-04\n",
            "Epoch 18/100\n",
            " - 6s - loss: 8.7366e-04 - val_loss: 8.5916e-04\n",
            "Epoch 19/100\n",
            " - 6s - loss: 8.8060e-04 - val_loss: 8.5890e-04\n",
            "Epoch 20/100\n",
            " - 6s - loss: 8.8149e-04 - val_loss: 8.6696e-04\n",
            "Epoch 21/100\n",
            " - 6s - loss: 8.7564e-04 - val_loss: 8.7364e-04\n",
            "Epoch 22/100\n",
            " - 6s - loss: 8.9369e-04 - val_loss: 8.5620e-04\n",
            "Epoch 23/100\n",
            " - 6s - loss: 8.8995e-04 - val_loss: 8.7726e-04\n",
            "Epoch 24/100\n",
            " - 6s - loss: 8.7868e-04 - val_loss: 8.6884e-04\n",
            "Epoch 25/100\n",
            " - 6s - loss: 8.8331e-04 - val_loss: 8.6362e-04\n",
            "Epoch 26/100\n",
            " - 6s - loss: 8.8359e-04 - val_loss: 9.1387e-04\n",
            "Epoch 27/100\n",
            " - 6s - loss: 8.8492e-04 - val_loss: 8.4868e-04\n",
            "Epoch 28/100\n",
            " - 6s - loss: 8.9569e-04 - val_loss: 8.7688e-04\n",
            "Epoch 29/100\n",
            " - 6s - loss: 8.7494e-04 - val_loss: 8.7744e-04\n",
            "Epoch 30/100\n",
            " - 6s - loss: 8.7208e-04 - val_loss: 8.7938e-04\n",
            "Epoch 31/100\n",
            " - 6s - loss: 8.8319e-04 - val_loss: 8.3992e-04\n",
            "Epoch 32/100\n",
            " - 6s - loss: 8.8991e-04 - val_loss: 8.5990e-04\n",
            "Epoch 33/100\n",
            " - 6s - loss: 8.6719e-04 - val_loss: 8.6693e-04\n",
            "Epoch 34/100\n",
            " - 6s - loss: 8.6772e-04 - val_loss: 8.4756e-04\n",
            "Epoch 35/100\n",
            " - 6s - loss: 8.6987e-04 - val_loss: 8.8050e-04\n",
            "Epoch 36/100\n",
            " - 6s - loss: 8.6944e-04 - val_loss: 8.6568e-04\n",
            "Epoch 37/100\n",
            " - 6s - loss: 8.6776e-04 - val_loss: 8.5390e-04\n",
            "Epoch 38/100\n",
            " - 6s - loss: 8.8326e-04 - val_loss: 8.6751e-04\n",
            "Epoch 39/100\n",
            " - 6s - loss: 8.6803e-04 - val_loss: 8.5254e-04\n",
            "Epoch 40/100\n",
            " - 6s - loss: 8.8438e-04 - val_loss: 8.5246e-04\n",
            "Epoch 41/100\n",
            " - 6s - loss: 8.8615e-04 - val_loss: 8.5501e-04\n",
            "Epoch 42/100\n",
            " - 6s - loss: 8.8067e-04 - val_loss: 8.5552e-04\n",
            "Epoch 43/100\n",
            " - 6s - loss: 8.5587e-04 - val_loss: 8.7147e-04\n",
            "Epoch 44/100\n",
            " - 6s - loss: 8.7524e-04 - val_loss: 8.4903e-04\n",
            "Epoch 45/100\n",
            " - 6s - loss: 8.7634e-04 - val_loss: 8.5006e-04\n",
            "Epoch 46/100\n",
            " - 6s - loss: 8.8176e-04 - val_loss: 8.3574e-04\n",
            "Epoch 47/100\n",
            " - 6s - loss: 8.8295e-04 - val_loss: 8.9335e-04\n",
            "Epoch 48/100\n",
            " - 6s - loss: 8.7359e-04 - val_loss: 8.6648e-04\n",
            "Epoch 49/100\n",
            " - 6s - loss: 8.6652e-04 - val_loss: 8.5558e-04\n",
            "Epoch 50/100\n",
            " - 6s - loss: 8.9292e-04 - val_loss: 8.5364e-04\n",
            "Epoch 51/100\n",
            " - 6s - loss: 8.7746e-04 - val_loss: 8.9250e-04\n",
            "Epoch 52/100\n",
            " - 6s - loss: 9.1680e-04 - val_loss: 8.6264e-04\n",
            "Epoch 53/100\n",
            " - 6s - loss: 8.7469e-04 - val_loss: 9.1109e-04\n",
            "Epoch 54/100\n",
            " - 6s - loss: 8.6658e-04 - val_loss: 8.5485e-04\n",
            "Epoch 55/100\n",
            " - 6s - loss: 8.6643e-04 - val_loss: 8.8252e-04\n",
            "Epoch 56/100\n",
            " - 6s - loss: 8.7102e-04 - val_loss: 8.5777e-04\n",
            "Epoch 57/100\n",
            " - 6s - loss: 8.7663e-04 - val_loss: 8.5275e-04\n",
            "Epoch 58/100\n",
            " - 6s - loss: 8.5432e-04 - val_loss: 8.3618e-04\n",
            "Epoch 59/100\n",
            " - 6s - loss: 9.0359e-04 - val_loss: 9.0998e-04\n",
            "Epoch 60/100\n",
            " - 6s - loss: 8.9024e-04 - val_loss: 8.6715e-04\n",
            "Epoch 61/100\n",
            " - 6s - loss: 8.8542e-04 - val_loss: 8.5749e-04\n",
            "Epoch 62/100\n",
            " - 6s - loss: 8.6846e-04 - val_loss: 8.8501e-04\n",
            "Epoch 63/100\n",
            " - 6s - loss: 8.6698e-04 - val_loss: 8.5111e-04\n",
            "Epoch 64/100\n",
            " - 6s - loss: 8.5914e-04 - val_loss: 8.4893e-04\n",
            "Epoch 65/100\n",
            " - 6s - loss: 8.6257e-04 - val_loss: 8.6908e-04\n",
            "Epoch 66/100\n",
            " - 6s - loss: 8.7843e-04 - val_loss: 8.8832e-04\n",
            "Epoch 67/100\n",
            " - 6s - loss: 8.6805e-04 - val_loss: 8.4277e-04\n",
            "Epoch 68/100\n",
            " - 6s - loss: 8.8416e-04 - val_loss: 8.6447e-04\n",
            "Epoch 69/100\n",
            " - 6s - loss: 8.8263e-04 - val_loss: 8.7402e-04\n",
            "Epoch 70/100\n",
            " - 6s - loss: 8.7971e-04 - val_loss: 8.6887e-04\n",
            "Epoch 71/100\n",
            " - 6s - loss: 8.6105e-04 - val_loss: 9.1220e-04\n",
            "Epoch 72/100\n",
            " - 6s - loss: 8.8013e-04 - val_loss: 8.7640e-04\n",
            "Epoch 73/100\n",
            " - 6s - loss: 8.8315e-04 - val_loss: 9.0605e-04\n",
            "Epoch 74/100\n",
            " - 6s - loss: 9.4508e-04 - val_loss: 8.4970e-04\n",
            "Epoch 75/100\n",
            " - 6s - loss: 8.6527e-04 - val_loss: 8.7509e-04\n",
            "Epoch 76/100\n",
            " - 6s - loss: 8.9925e-04 - val_loss: 8.4031e-04\n",
            "Epoch 77/100\n",
            " - 6s - loss: 8.5889e-04 - val_loss: 8.7227e-04\n",
            "Epoch 78/100\n",
            " - 6s - loss: 8.7442e-04 - val_loss: 8.9250e-04\n",
            "Epoch 79/100\n",
            " - 6s - loss: 8.6467e-04 - val_loss: 8.6099e-04\n",
            "Epoch 80/100\n",
            " - 6s - loss: 8.7841e-04 - val_loss: 8.5309e-04\n",
            "Epoch 81/100\n",
            " - 6s - loss: 8.5197e-04 - val_loss: 8.8345e-04\n",
            "Epoch 82/100\n",
            " - 6s - loss: 8.7371e-04 - val_loss: 8.4046e-04\n",
            "Epoch 83/100\n",
            " - 6s - loss: 8.7504e-04 - val_loss: 8.3515e-04\n",
            "Epoch 84/100\n",
            " - 6s - loss: 8.6356e-04 - val_loss: 8.4065e-04\n",
            "Epoch 85/100\n",
            " - 6s - loss: 8.5282e-04 - val_loss: 8.5434e-04\n",
            "Epoch 86/100\n",
            " - 6s - loss: 8.6524e-04 - val_loss: 8.6822e-04\n",
            "Epoch 87/100\n",
            " - 6s - loss: 8.6857e-04 - val_loss: 8.5695e-04\n",
            "Epoch 88/100\n",
            " - 6s - loss: 8.7117e-04 - val_loss: 8.5605e-04\n",
            "Epoch 89/100\n",
            " - 6s - loss: 8.6369e-04 - val_loss: 8.6321e-04\n",
            "Epoch 90/100\n",
            " - 6s - loss: 8.5776e-04 - val_loss: 8.6260e-04\n",
            "Epoch 91/100\n",
            " - 6s - loss: 8.6705e-04 - val_loss: 8.5786e-04\n",
            "Epoch 92/100\n",
            " - 6s - loss: 8.5859e-04 - val_loss: 8.9110e-04\n",
            "Epoch 93/100\n",
            " - 6s - loss: 8.7163e-04 - val_loss: 8.4934e-04\n",
            "Epoch 94/100\n",
            " - 6s - loss: 8.5693e-04 - val_loss: 8.7069e-04\n",
            "Epoch 95/100\n",
            " - 6s - loss: 8.7000e-04 - val_loss: 8.3923e-04\n",
            "Epoch 96/100\n",
            " - 6s - loss: 8.6209e-04 - val_loss: 8.7191e-04\n",
            "Epoch 97/100\n",
            " - 6s - loss: 8.7765e-04 - val_loss: 8.6420e-04\n",
            "Epoch 98/100\n",
            " - 6s - loss: 8.6683e-04 - val_loss: 8.6089e-04\n",
            "Epoch 99/100\n",
            " - 6s - loss: 8.6576e-04 - val_loss: 8.2733e-04\n",
            "Epoch 100/100\n",
            " - 6s - loss: 8.6656e-04 - val_loss: 8.2801e-04\n",
            "Test r2 score: 0.9418584675426599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5SCd257CS7E",
        "colab_type": "code",
        "outputId": "198d792f-84d0-46f6-8e3e-0a0d3eed2034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_y = model.predict(test_x)\n",
        "score = r2_score(test_y, pred_y)\n",
        "print(f'Test r2 score: {score}')\n",
        "\n",
        "#model.save('final'+model_name)\n"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test r2 score: 0.9418584675426599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-x1BEeFNOYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "cfa473d9-357f-42b3-a107-41e2f7edea92"
      },
      "source": [
        "test_mini_df = read_dataset('PageRank_test_jb_mini_test_1.csv')\n",
        "#jobs = test_mini_df['job']\n",
        "#del test_mini_df['job']\n",
        "\n",
        "#get original test_df\n",
        "test_df['flow_size'] = pred_y\n",
        "#print(test_df.tail())\n",
        "unscaled_test_df = scaler.inverse_transform(test_df)\n",
        "unscaled_test_df = pd.DataFrame(unscaled_test_df, columns = cols)\n",
        "#change_cols = {\"agg_net_out\":'int32', \"agg_net_in\":'int32', \"agg_net_out_per_machine\":'int32','agg_net_in_per_machine':'int32','machine':'int32','flow_size':'int32'}\n",
        "#unscaled_test_df = unscaled_test_df.astype(change_cols)\n",
        "unscaled_test_df.tail(20)\n"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>flow_frequency</th>\n",
              "      <th>agg_net_out</th>\n",
              "      <th>agg_net_in</th>\n",
              "      <th>agg_net_out_per_machine</th>\n",
              "      <th>agg_net_in_per_machine</th>\n",
              "      <th>machine</th>\n",
              "      <th>flow_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14794</th>\n",
              "      <td>102.15</td>\n",
              "      <td>7.65</td>\n",
              "      <td>190811027.0</td>\n",
              "      <td>767966981.0</td>\n",
              "      <td>1811577.0</td>\n",
              "      <td>1687049.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14795</th>\n",
              "      <td>102.25</td>\n",
              "      <td>0.10</td>\n",
              "      <td>191735863.0</td>\n",
              "      <td>767980802.0</td>\n",
              "      <td>7895583.0</td>\n",
              "      <td>178595.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14796</th>\n",
              "      <td>102.45</td>\n",
              "      <td>0.15</td>\n",
              "      <td>193350507.0</td>\n",
              "      <td>768003686.0</td>\n",
              "      <td>8375499.0</td>\n",
              "      <td>179687.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14797</th>\n",
              "      <td>102.55</td>\n",
              "      <td>0.10</td>\n",
              "      <td>194156699.0</td>\n",
              "      <td>768016991.0</td>\n",
              "      <td>8532039.0</td>\n",
              "      <td>179739.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14798</th>\n",
              "      <td>102.65</td>\n",
              "      <td>0.10</td>\n",
              "      <td>194912748.0</td>\n",
              "      <td>768027205.0</td>\n",
              "      <td>8794443.0</td>\n",
              "      <td>180467.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14799</th>\n",
              "      <td>102.85</td>\n",
              "      <td>0.20</td>\n",
              "      <td>196427263.0</td>\n",
              "      <td>768052271.0</td>\n",
              "      <td>9056847.0</td>\n",
              "      <td>181351.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14800</th>\n",
              "      <td>103.00</td>\n",
              "      <td>0.10</td>\n",
              "      <td>198154419.0</td>\n",
              "      <td>768072334.0</td>\n",
              "      <td>9844059.0</td>\n",
              "      <td>183587.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14801</th>\n",
              "      <td>103.20</td>\n",
              "      <td>1.05</td>\n",
              "      <td>200738883.0</td>\n",
              "      <td>768103241.0</td>\n",
              "      <td>1813039.0</td>\n",
              "      <td>1687273.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14802</th>\n",
              "      <td>103.40</td>\n",
              "      <td>0.10</td>\n",
              "      <td>202968838.0</td>\n",
              "      <td>768130312.0</td>\n",
              "      <td>12349199.0</td>\n",
              "      <td>192427.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14803</th>\n",
              "      <td>107.20</td>\n",
              "      <td>4.00</td>\n",
              "      <td>239656636.0</td>\n",
              "      <td>768647476.0</td>\n",
              "      <td>1814501.0</td>\n",
              "      <td>1687497.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14804</th>\n",
              "      <td>107.80</td>\n",
              "      <td>0.60</td>\n",
              "      <td>245917237.0</td>\n",
              "      <td>768735687.0</td>\n",
              "      <td>1815963.0</td>\n",
              "      <td>1687721.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14805</th>\n",
              "      <td>109.50</td>\n",
              "      <td>1.70</td>\n",
              "      <td>266029583.0</td>\n",
              "      <td>768990194.0</td>\n",
              "      <td>1820029.0</td>\n",
              "      <td>1687773.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14806</th>\n",
              "      <td>111.10</td>\n",
              "      <td>1.60</td>\n",
              "      <td>297423788.0</td>\n",
              "      <td>769268473.0</td>\n",
              "      <td>1821605.0</td>\n",
              "      <td>1687825.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14807</th>\n",
              "      <td>111.25</td>\n",
              "      <td>0.15</td>\n",
              "      <td>301173758.0</td>\n",
              "      <td>769291201.0</td>\n",
              "      <td>1828480.0</td>\n",
              "      <td>1688083.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14808</th>\n",
              "      <td>112.65</td>\n",
              "      <td>1.40</td>\n",
              "      <td>301187008.0</td>\n",
              "      <td>769292873.0</td>\n",
              "      <td>1839536.0</td>\n",
              "      <td>1688635.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14809</th>\n",
              "      <td>113.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>301215840.0</td>\n",
              "      <td>769359493.0</td>\n",
              "      <td>1868368.0</td>\n",
              "      <td>1755255.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14810</th>\n",
              "      <td>113.30</td>\n",
              "      <td>0.15</td>\n",
              "      <td>301235805.0</td>\n",
              "      <td>769383028.0</td>\n",
              "      <td>1888333.0</td>\n",
              "      <td>1778790.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14811</th>\n",
              "      <td>113.60</td>\n",
              "      <td>0.25</td>\n",
              "      <td>301255874.0</td>\n",
              "      <td>769383288.0</td>\n",
              "      <td>1908402.0</td>\n",
              "      <td>1779050.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14812</th>\n",
              "      <td>113.75</td>\n",
              "      <td>38.40</td>\n",
              "      <td>301267361.0</td>\n",
              "      <td>769383444.0</td>\n",
              "      <td>81907.0</td>\n",
              "      <td>155879.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14813</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         time  flow_frequency  ...  machine  flow_size\n",
              "14794  102.15            7.65  ...      4.0     1002.0\n",
              "14795  102.25            0.10  ...      5.0     1002.0\n",
              "14796  102.45            0.15  ...      5.0     1002.0\n",
              "14797  102.55            0.10  ...      5.0     1002.0\n",
              "14798  102.65            0.10  ...      5.0     1002.0\n",
              "14799  102.85            0.20  ...      5.0     1002.0\n",
              "14800  103.00            0.10  ...      5.0     1002.0\n",
              "14801  103.20            1.05  ...      4.0     1002.0\n",
              "14802  103.40            0.10  ...      5.0     1002.0\n",
              "14803  107.20            4.00  ...      4.0     1002.0\n",
              "14804  107.80            0.60  ...      4.0     1002.0\n",
              "14805  109.50            1.70  ...      4.0     1002.0\n",
              "14806  111.10            1.60  ...      4.0     1002.0\n",
              "14807  111.25            0.15  ...      4.0     1002.0\n",
              "14808  112.65            1.40  ...      4.0     1002.0\n",
              "14809  113.15            0.50  ...      4.0     1002.0\n",
              "14810  113.30            0.15  ...      4.0     1002.0\n",
              "14811  113.60            0.25  ...      4.0     1002.0\n",
              "14812  113.75           38.40  ...      0.0     1002.0\n",
              "14813    0.00            0.00  ...      0.0     1002.0\n",
              "\n",
              "[20 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_N3E_AvPKag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "418aa018-fa4f-4b27-94ac-74592cde4dee"
      },
      "source": [
        "unscaled_test_df.loc[unscaled_test_df['flow_size'].idxmax()]"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "time                       1.385500e+02\n",
              "flow_frequency             1.320000e+01\n",
              "agg_net_out                1.027385e+08\n",
              "agg_net_in                 1.369980e+09\n",
              "agg_net_out_per_machine    3.154502e+06\n",
              "agg_net_in_per_machine     3.080607e+06\n",
              "machine                    4.000000e+00\n",
              "flow_size                  4.114875e+08\n",
              "Name: 1942, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXekpHCWUZ7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff954ef0-a098-411a-d19e-f0427a891b6a"
      },
      "source": [
        "unscaled_test_df.loc[1942]['flow_size']"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "411487522.8759811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv75zRlROXrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df = pd.DataFrame([])\n",
        "new_df['flow_size'] = test_mini_df['flow_size']\n",
        "new_df['job'] = test_mini_df['job']\n",
        "new_df['predicted_flow_size'] = test_mini_df['flow_size']\n",
        "\n",
        "#now copy predicted\n",
        "for index, row in test_mini_df.iterrows():\n",
        "  i = int(row['pseudo_index'])\n",
        "  new_df.iloc[index,2] = unscaled_test_df.iloc[i]['flow_size']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wbQ_abZCvNN",
        "colab_type": "code",
        "outputId": "d524645f-6c85-4d8f-e207-f4a6e5a6f80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "new_df.head(10)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flow_size</th>\n",
              "      <th>job</th>\n",
              "      <th>predicted_flow_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1576.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2777.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4763.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.000215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1494.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.001862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30717.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.001983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3560.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.002916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15372.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.001450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>22817.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2061.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1576.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1002.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   flow_size  job  predicted_flow_size\n",
              "0     1576.0    1          1002.000001\n",
              "1     2777.0    1          1002.000002\n",
              "2     4763.0    1          1002.000215\n",
              "3     1494.0    1          1002.001862\n",
              "4    30717.0    1          1002.001983\n",
              "5     3560.0    1          1002.002916\n",
              "6    15372.0    1          1002.001450\n",
              "7    22817.0    1          1002.000000\n",
              "8     2061.0    1          1002.000000\n",
              "9     1576.0    1          1002.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AktG5KnD9wXq",
        "colab_type": "code",
        "outputId": "8358434a-82b5-443e-9c06-b946fa4fbee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_mini_df.head()"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pseudo_index</th>\n",
              "      <th>time</th>\n",
              "      <th>flow_frequency</th>\n",
              "      <th>agg_net_out</th>\n",
              "      <th>agg_net_in</th>\n",
              "      <th>agg_net_out_per_machine</th>\n",
              "      <th>agg_net_in_per_machine</th>\n",
              "      <th>machine</th>\n",
              "      <th>flow_size</th>\n",
              "      <th>job</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14.50</td>\n",
              "      <td>4.80</td>\n",
              "      <td>1576.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1576.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1576.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>16.25</td>\n",
              "      <td>1.75</td>\n",
              "      <td>4353.0</td>\n",
              "      <td>3078.0</td>\n",
              "      <td>4353.0</td>\n",
              "      <td>3078.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2777.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>16.55</td>\n",
              "      <td>0.15</td>\n",
              "      <td>9116.0</td>\n",
              "      <td>5207.0</td>\n",
              "      <td>9116.0</td>\n",
              "      <td>5207.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4763.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>16.80</td>\n",
              "      <td>0.25</td>\n",
              "      <td>10610.0</td>\n",
              "      <td>5431.0</td>\n",
              "      <td>10610.0</td>\n",
              "      <td>5431.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1494.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>41327.0</td>\n",
              "      <td>72699.0</td>\n",
              "      <td>41327.0</td>\n",
              "      <td>72699.0</td>\n",
              "      <td>4</td>\n",
              "      <td>30717.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pseudo_index   time  flow_frequency  ...  machine  flow_size  job\n",
              "0             0  14.50            4.80  ...        4     1576.0    1\n",
              "1             1  16.25            1.75  ...        4     2777.0    1\n",
              "2             2  16.55            0.15  ...        4     4763.0    1\n",
              "3             3  16.80            0.25  ...        4     1494.0    1\n",
              "4             4  17.10            0.10  ...        4    30717.0    1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD2nEl4o-QvK",
        "colab_type": "code",
        "outputId": "1b561aec-c66b-4d40-a3a5-57b77649b715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "unscaled_test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>flow_frequency</th>\n",
              "      <th>agg_net_out</th>\n",
              "      <th>agg_net_in</th>\n",
              "      <th>agg_net_out_per_machine</th>\n",
              "      <th>agg_net_in_per_machine</th>\n",
              "      <th>machine</th>\n",
              "      <th>flow_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.50</td>\n",
              "      <td>4.80</td>\n",
              "      <td>1576</td>\n",
              "      <td>52</td>\n",
              "      <td>1576</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>1576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.25</td>\n",
              "      <td>1.75</td>\n",
              "      <td>4353</td>\n",
              "      <td>3078</td>\n",
              "      <td>4353</td>\n",
              "      <td>3078</td>\n",
              "      <td>4</td>\n",
              "      <td>2777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.55</td>\n",
              "      <td>0.15</td>\n",
              "      <td>9116</td>\n",
              "      <td>5207</td>\n",
              "      <td>9116</td>\n",
              "      <td>5207</td>\n",
              "      <td>4</td>\n",
              "      <td>4762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.80</td>\n",
              "      <td>0.25</td>\n",
              "      <td>10610</td>\n",
              "      <td>5431</td>\n",
              "      <td>10610</td>\n",
              "      <td>5431</td>\n",
              "      <td>4</td>\n",
              "      <td>1494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>41327</td>\n",
              "      <td>72699</td>\n",
              "      <td>41327</td>\n",
              "      <td>72699</td>\n",
              "      <td>4</td>\n",
              "      <td>30717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    time  flow_frequency  ...  machine  flow_size\n",
              "0  14.50            4.80  ...        4       1576\n",
              "1  16.25            1.75  ...        4       2777\n",
              "2  16.55            0.15  ...        4       4762\n",
              "3  16.80            0.25  ...        4       1494\n",
              "4  17.10            0.10  ...        4      30717\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXtyyHzgRpNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df.to_csv('PageRank_test_jb_mini_predicted_no_outliers.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Oo1ljlSybZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}